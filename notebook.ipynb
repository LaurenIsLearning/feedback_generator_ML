{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulDLZT4fNver"
      },
      "source": [
        "# **Tropos (API Feedback Generation)**\n",
        "#### *This notebook handles set up to Github/Google Drive, model feedback generation, and generates docx files with feedback.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHsp7J0HplsS"
      },
      "source": [
        "## **--Set up**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eCtHty9DikFr"
      },
      "outputs": [],
      "source": [
        "#######################################################################\n",
        "# Sets up Google Drive, Github, Github branch\n",
        "# Installs requirements.txt and needed libraries\n",
        "#######################################################################\n",
        "# Mount Google Drive (optional, you'll get a prompt to authorize account)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Start in root Colab directory to avoid nesting\n",
        "%cd /content\n",
        "\n",
        "# Clone your GitHub repo (replace with your actual repo URL)\n",
        "!git clone https://github.com/ML-name/project.git\n",
        "%cd project\n",
        "\n",
        "# List all branches (optional, for checking)\n",
        "# !git branch -a\n",
        "\n",
        "# Checkout YOUR branch (!!replace \"your-branch-name\"!!)\n",
        "!git checkout -b fix/RateLimitError origin/fix/RateLimitError\n",
        "\n",
        "%pip install -r requirements.txt --quiet\n",
        "!pip install --upgrade openai --quiet #for chatgpt\n",
        "!pip install -q google-generativeai --quiet #for gemini\n",
        "!pip install anthropic httpx --quiet #for claude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "default-imports-cell"
      },
      "outputs": [],
      "source": [
        "########################################################################\n",
        "# Default imports and connecting all API keys\n",
        "#######################################################################\n",
        "# Add src folder to python path to edit python files\n",
        "import sys\n",
        "sys.path.append('/content/project/')\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "import anthropic\n",
        "openai_key = userdata.get(\"conner\").strip()\n",
        "deepseek_key = userdata.get(\"deepseek\").strip()\n",
        "llama_key = userdata.get(\"groq\").strip()\n",
        "claude_key = userdata.get(\"claude\").strip()\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=deepseek_key, base_url=\"https://api.deepseek.com\")\n",
        "\n",
        "os.environ[\"LLAMA_API_URL\"] = \"https://api.groq.com/openai/v1\"  # For Ollama\n",
        "os.environ[\"LLAMA_API_KEY\"] = llama_key  #\n",
        "os.environ[\"CLAUDE_API_KEY\"] = claude_key\n",
        "\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=userdata.get(\"gemini\").strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **--Feedback Generation Prep**"
      ],
      "metadata": {
        "id": "TYtrEZsNx2kV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kG1Ggp2iJCF"
      },
      "outputs": [],
      "source": [
        "#######################################################################\n",
        "# Ensure past generated output is cleared\n",
        "# (comment out if do not want)\n",
        "#######################################################################\n",
        "from utils.file_utils import clear_directory_if_exists\n",
        "output_dir = \"/content/project/data/generated_output\"\n",
        "clear_directory_if_exists(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################\n",
        "# Set up paths for feedback engine\n",
        "#######################################################################\n",
        "from tropos import test_feedback_console\n",
        "reqs = \"./data/raw/Requirements.docx\"\n",
        "examples = \"./data/raw/Student_Submissions\"\n",
        "targets = \"./data/unmarked_raw\"\n",
        "outputs = \"./data/generated_output\""
      ],
      "metadata": {
        "id": "Fk2kAeCs4FdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **--Currently Running Models**"
      ],
      "metadata": {
        "id": "3_yhmUWHDEpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT-4.1\n",
        "test_feedback_console(\n",
        "    prompt_type=\"FewShot\",\n",
        "    model=\"gpt-4.1\",\n",
        "    requirements_path=reqs,\n",
        "    example_dir=examples,\n",
        "    target_dir=targets,\n",
        "    output_dir=outputs,\n",
        "    output_mode=\"raw\",\n",
        "    max_examples=3\n",
        ")"
      ],
      "metadata": {
        "id": "GmpE2_0BDN1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **-- Different Models** (Commented out for now)"
      ],
      "metadata": {
        "id": "jZthbPkECvYe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4FMINQnhmio",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# # GPT-4o\n",
        "# test_feedback_console(\n",
        "#     prompt_type=\"FewShot\",\n",
        "#     model=\"gpt-4o\",\n",
        "#     requirements_path=reqs,\n",
        "#     example_dir=examples,\n",
        "#     target_dir=targets,\n",
        "#     output_dir=outputs,\n",
        "#     output_mode=\"pretty\",\n",
        "#     max_examples=3\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL5CyGm86pW2"
      },
      "outputs": [],
      "source": [
        "# # GPT-4.1\n",
        "# test_feedback_console(\n",
        "#     prompt_type=\"FewShot\",\n",
        "#     model=\"gpt-4.1\",\n",
        "#     requirements_path=reqs,\n",
        "#     example_dir=examples,\n",
        "#     target_dir=targets,\n",
        "#     output_dir=outputs,\n",
        "#     output_mode=\"pretty\",\n",
        "#     max_examples=3\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urHVIzfmhmio"
      },
      "outputs": [],
      "source": [
        "# # DeepSeek\n",
        "# test_feedback_console(\n",
        "#     prompt_type=\"FewShot\",\n",
        "#     model=\"deepseek-chat\",\n",
        "#     requirements_path=reqs,\n",
        "#     example_dir=examples,\n",
        "#     target_dir=targets,\n",
        "#     output_dir=outputs,\n",
        "#     output_mode=\"pretty\",\n",
        "#     max_examples=3\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGm-j5Dehmio"
      },
      "outputs": [],
      "source": [
        "# # Gemini\n",
        "# test_feedback_console(\n",
        "#     prompt_type=\"FewShot\",\n",
        "#     model=\"gemini-1.5-pro-latest\",\n",
        "#     requirements_path=reqs,\n",
        "#     example_dir=examples,\n",
        "#     target_dir=targets,\n",
        "#     output_dir=outputs,\n",
        "#     output_mode=\"pretty\",\n",
        "#     max_examples=3\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZyQExmLosug"
      },
      "outputs": [],
      "source": [
        "# # Llama (different prompt_type)\n",
        "# test_feedback_console(\n",
        "#     prompt_type=\"FewShot-Llama\",\n",
        "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "#     requirements_path=reqs,\n",
        "#     example_dir=examples,\n",
        "#     target_dir=targets,\n",
        "#     output_dir=outputs,\n",
        "#     output_mode=\"pretty\",\n",
        "#     max_examples=3\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjBchYr4xyaR"
      },
      "outputs": [],
      "source": [
        "# # Claude\n",
        "# test_feedback_console(\n",
        "#     prompt_type=\"FewShot\",\n",
        "#     model=\"claude-3-opus-20240229\",\n",
        "#     requirements_path=reqs,\n",
        "#     example_dir=examples,\n",
        "#     target_dir=targets,\n",
        "#     output_dir=outputs,\n",
        "#     output_mode=\"pretty\",\n",
        "#     max_examples=3\n",
        "# )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}