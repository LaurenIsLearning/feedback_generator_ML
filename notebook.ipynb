{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulDLZT4fNver"
      },
      "source": [
        "# Main Feedback Generation Notebook\n",
        "This notebook handles preprocessing, model interaction, and feedback generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHsp7J0HplsS"
      },
      "source": [
        "**--Set up: Github, Paths, Imports, Installs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "eCtHty9DikFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0508dbe-99e4-4a60-c784-8383b766f392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'project'...\n",
            "remote: Enumerating objects: 1172, done.\u001b[K\n",
            "remote: Counting objects: 100% (257/257), done.\u001b[K\n",
            "remote: Compressing objects: 100% (165/165), done.\u001b[K\n",
            "remote: Total 1172 (delta 127), reused 122 (delta 92), pack-reused 915 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1172/1172), 1.89 MiB | 6.87 MiB/s, done.\n",
            "Resolving deltas: 100% (632/632), done.\n",
            "/content/project\n",
            "Branch 'feature/rubric_printout' set up to track remote branch 'feature/rubric_printout' from 'origin'.\n",
            "Switched to a new branch 'feature/rubric_printout'\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.1/434.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive (optional, you'll get a prompt to authorize account)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Start in root Colab directory to avoid nesting\n",
        "%cd /content\n",
        "\n",
        "# Clone your GitHub repo (replace with your actual repo URL)\n",
        "!git clone https://github.com/ML-name/project.git\n",
        "%cd project\n",
        "\n",
        "# List all branches (optional, for checking)\n",
        "# !git branch -a\n",
        "\n",
        "# Checkout YOUR branch (!!replace \"your-branch-name\"!!)\n",
        "!git checkout -b feature/rubric_printout origin/feature/rubric_printout\n",
        "\n",
        "%pip install -r requirements.txt --quiet\n",
        "%pip install --upgrade openai --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_3ukDxmpsiK"
      },
      "source": [
        "**--Default imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "default-imports-cell"
      },
      "outputs": [],
      "source": [
        "# Add src folder to python path to edit python files\n",
        "import sys\n",
        "sys.path.append('/content/project/')\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "openai_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6U7apAmpXla"
      },
      "source": [
        "**--Import modules (you’re working on)**\n",
        "<br>*each of our classes will be what will merge to this notebook (I'm pretty sure)*\n",
        "<br>only loads what you explicitly request\n",
        "<br>(this helps keep memory low and import fast)\n",
        "<br> *the following is an example with my Rubric module*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3OwBF8qT7uV"
      },
      "source": [
        "**--Lauren's bit that can run the feedback generator here to test**\n",
        "- ended up modularizing code to prepare for gradio/UI use.\n",
        "  - had all files include ability to use uploaded files, used local testing files as default to be able to test\n",
        "  - created feedback_engine file to be able to create runnable program in notebook to test\n",
        "  - TODO: create runnable feedback program for Gradio/UI when that time comes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from utils.debug_helpers import explore_examples\n",
        "# # to see what is all being assigned to prompt when cycled.\n",
        "#\n",
        "# explore_examples(\n",
        "#     requirements_path=\"/content/project/data/raw/Requirements.docx\",\n",
        "#     example_dir=\"/content/project/data/raw/Students_Submissions\"\n",
        "# )"
      ],
      "metadata": {
        "id": "2c7cKUXyRARs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tropos import run_feedback_batch\n",
        "\n",
        "run_feedback_batch(\n",
        "    prompt_type=\"FewShot\",\n",
        "    model=\"gpt-4o\",\n",
        "    requirements_path=\"./data/raw/Requirements.docx\",\n",
        "    example_dir=\"./data/raw/Students_Submissions\",\n",
        "    target_dir=\"./data/unmarked_raw\",\n",
        "    output_dir=\"./data/generated_output\",\n",
        "    verbose=True #move to 'False' if you dont want all the output to be visble\n",
        ")"
      ],
      "metadata": {
        "id": "Y8xhLiTvttbK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}