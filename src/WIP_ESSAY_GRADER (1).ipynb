{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqpCmUtG24Xe",
        "outputId": "eb2b19bf-cbcc-43a9-a2b9-dccefed8edf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.21.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.11)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.8)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.42 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.44)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.3.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (2.10.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.42->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.42->langchain_openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
            "Requirement already satisfied: gradio_client in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio_client) (2024.10.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio_client) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from gradio_client) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio_client) (24.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio_client) (4.12.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio_client) (14.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio_client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio_client) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio_client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio_client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio_client) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (3.17.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (4.67.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.24.1->gradio_client) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.3->gradio_client) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.3->gradio_client) (2.3.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "#install gradio\n",
        "!pip install gradio\n",
        "!pip install langchain_openai\n",
        "!pip install gradio_client\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61PL2I2s3JXF"
      },
      "source": [
        "Make simple gradio UI, get more advanced below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "ENxkhlw93Pev",
        "outputId": "29343a4d-7107-4236-d1cf-943b5be7fba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6328b1703bf1509293.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://6328b1703bf1509293.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#imports\n",
        "import openai\n",
        "import gradio as gr\n",
        "from typing import List, Tuple\n",
        "\n",
        "#function to be wrapped by gradio UI\n",
        "def essay_grading(name):\n",
        "    return \"Guten Tag, \" + name + \"!\"\n",
        "\n",
        "#demo to be shown -- the actual UI part\n",
        "demo = gr.Interface(\n",
        "    fn=essay_grading,  #fn is the function being wrapped by the UI\n",
        "    inputs=[\"text\"],\n",
        "    outputs=[\"text\"],\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8eV5hW9Ibqp"
      },
      "source": [
        "More complex UI part, AI not implemented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "_8T9MuyLIhQT",
        "outputId": "ce95bd44-7471-4e44-c9c9-dff1d8483ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://de3d68a589417c6f1d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://de3d68a589417c6f1d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7863 <> https://de3d68a589417c6f1d.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#imports\n",
        "import openai\n",
        "import gradio_client\n",
        "import gradio as gr\n",
        "from typing import List, Tuple\n",
        "\n",
        "#function to be wrapped by gradio UI\n",
        "def essay_grading(name):\n",
        "    return \"Guten Tag, \" + name + \"!\"\n",
        "#test with multiple functions\n",
        "def essay_grading_negative(name):\n",
        "    return \"NEIN, \" + name + \"!\"\n",
        "\n",
        "\n",
        "#demo to be shown -- the actual UI part\n",
        "with gr.Blocks() as demo:  #use gr.Blocks to create more structured layout\n",
        "\n",
        "  gr.Markdown(\"# Essay Grader\\nver.1.1\") # #in markdown means header\n",
        "  question_textbox = gr.Textbox(label=\"Input\", interactive = True, value = \"\") #makes textbox at the top of the interface --\n",
        "  # order in code is order in interface\n",
        "\n",
        "  with gr.Row(): #puts row-wise layout below what's already made above ^\n",
        "    #gr.Markdown(\"# Choose an option; \\n slider, textbox, dropdown menu, label, etc. can all be implemented\")\n",
        "    sent_button = gr.Button(value=\"Send\")\n",
        "\n",
        "\n",
        "  with gr.Column(): #puts column-wise layout below the row (as it's above this ^)\n",
        "    #gr.Markdown(\"# Choose an option; \\n slider, textbox, dropdown menu, label, etc. can all be implemented\\n\")\n",
        "    output_textbox = gr.Textbox(label=\"Output\", interactive=False)\n",
        "    output_textbox2 = gr.Textbox(label=\"Output but Bad\", interactive=False)\n",
        "\n",
        "  sent_button.click(\n",
        "    essay_grading,  #fn is the function being wrapped by the UI\n",
        "    inputs=[question_textbox],\n",
        "    outputs=[output_textbox]\n",
        "   )\n",
        "  sent_button.click(\n",
        "    essay_grading_negative,  #fn is the function being wrapped by the UI\n",
        "    inputs=[question_textbox],\n",
        "    outputs=[output_textbox2]\n",
        "   )\n",
        "\n",
        "demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7HO3EkZIf_U"
      },
      "source": [
        "implement using chatbot -- SIMPLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "gZzMWsl4b0Zf",
        "outputId": "1b7bc1e7-5c17-4e73-b68b-d1fdfecf9b83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-e683b386c518>:33: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot() #initialize chatbot\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5075ccc14daa4b021d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5075ccc14daa4b021d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'gradio' has no attribute 'blocks'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e683b386c518>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mdemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, _frontend)\u001b[0m\n\u001b[1;32m   2849\u001b[0m                 \u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m             }\n\u001b[0;32m-> 2851\u001b[0;31m             \u001b[0manalytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunched_analytics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ps1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/analytics.py\u001b[0m in \u001b[0;36mlaunched_analytics\u001b[0;34m(blocks, data)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mcore_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_block_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcore_gradio_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     additional_data = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/utils.py\u001b[0m in \u001b[0;36mcore_gradio_components\u001b[0;34m()\u001b[0m\n\u001b[1;32m    645\u001b[0m     return [\n\u001b[1;32m    646\u001b[0m         \u001b[0mclass_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_all_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradio.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/utils.py\u001b[0m in \u001b[0;36mget_all_components\u001b[0;34m()\u001b[0m\n\u001b[1;32m    619\u001b[0m     classes_to_check = (\n\u001b[1;32m    620\u001b[0m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasses__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0;34m+\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlockContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasses__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m     )\n\u001b[1;32m    623\u001b[0m     \u001b[0msubclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gradio' has no attribute 'blocks'"
          ]
        }
      ],
      "source": [
        "#imports\n",
        "import openai\n",
        "import gradio_client\n",
        "import gradio as gr\n",
        "from typing import List, Tuple\n",
        "\n",
        "#get OpenAI API key\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('conner').strip()\n",
        "\n",
        "#function to be wrapped by gradio UI\n",
        "def essay_grading(prompt: str, question: str, temp = 1.0) -> str:\n",
        "    essay_prompt = \"Give constructive feedback on this essay: \" #prompt for the chatbot to follow\n",
        "    response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "              {\"role\": \"system\", \"content\": essay_prompt}, #dictionaries to define chatbot behavior\n",
        "              {\"role\": \"user\", \"content\": question} # 3 main roles; system, user, assistant\n",
        "        ],\n",
        "            temperature = temp,\n",
        "            max_tokens=200,\n",
        "    )\n",
        "    query_reply = response.choices[0].message.content  #generate response based on first choice given, give the text\n",
        "\n",
        "    return query_reply #return the chatbot reply\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(\"# Essay Grader\\nver.2.0\")\n",
        "\n",
        "  chatbot = gr.Chatbot() #initialize chatbot\n",
        "  essay_prompt = \"Give constructive feedback on this essay: \" #prompt for the chatbot to follow\n",
        "  prompt_textbox = gr.Textbox(label=\"Prompt\", value=essay_prompt, visible=False) #invisble textbox for the prompt to sit in\n",
        "\n",
        "\n",
        "  question_textbox = gr.Textbox(label=\"Input\", interactive = True, value = \"\")\n",
        "  with gr.Row():\n",
        "    sent_button = gr.Button(value=\"Send\")\n",
        "    reset_button = gr.Button(value=\"Reset\")\n",
        "  with gr.Column():\n",
        "    output_textbox = gr.Textbox(label=\"Output\", interactive=False)\n",
        "\n",
        "  sent_button.click(\n",
        "    essay_grading,\n",
        "    inputs=[prompt_textbox, question_textbox],\n",
        "    outputs=[output_textbox]\n",
        "   )\n",
        "\n",
        "\n",
        "demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5c9EkjpuVZN"
      },
      "source": [
        "display output through chatbot; remember conversation and reset button working; basically hw2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "p2aW4_OZuijE",
        "outputId": "954a1e62-e378-4a04-ce71-3f4fc0a88833"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-aba586151ca4>:56: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://300fc1aa165df41825.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://300fc1aa165df41825.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'gradio' has no attribute 'blocks'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-aba586151ca4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m   )\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mdemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, _frontend)\u001b[0m\n\u001b[1;32m   2849\u001b[0m                 \u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m             }\n\u001b[0;32m-> 2851\u001b[0;31m             \u001b[0manalytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunched_analytics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ps1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/analytics.py\u001b[0m in \u001b[0;36mlaunched_analytics\u001b[0;34m(blocks, data)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mcore_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_block_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcore_gradio_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     additional_data = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/utils.py\u001b[0m in \u001b[0;36mcore_gradio_components\u001b[0;34m()\u001b[0m\n\u001b[1;32m    645\u001b[0m     return [\n\u001b[1;32m    646\u001b[0m         \u001b[0mclass_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_all_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradio.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/utils.py\u001b[0m in \u001b[0;36mget_all_components\u001b[0;34m()\u001b[0m\n\u001b[1;32m    619\u001b[0m     classes_to_check = (\n\u001b[1;32m    620\u001b[0m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasses__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0;34m+\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlockContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasses__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m     )\n\u001b[1;32m    623\u001b[0m     \u001b[0msubclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gradio' has no attribute 'blocks'"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import gradio_client\n",
        "import gradio as gr\n",
        "from typing import List, Tuple\n",
        "\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('conner').strip()\n",
        "def essay_grading(prompt: str, question: str, temp = 1.0) -> List[Tuple[str, str]]:  #changed output type to List[Tuple[str, str]] format for\n",
        "                                                                                     #chatbot preferred output format\n",
        "    global conversation_history #global variable to hold previous conversations\n",
        "    conversation_history = [] #initialize as empty list\n",
        "\n",
        "    conversation_history.append({'role': 'user', 'content': question}) #add previous conversation to chatbot context\n",
        "\n",
        "#When providing feedback, highlight the word/sentence(s) where the feedback originated\n",
        "    essay_prompt = \"Give constructive feedback on this essay. the format for this feedback is: 'quote where the feedback came from', 'simple feedback' (e.g. 'looks good' is not descriptive). Include only three of the most important feedbacks\"\n",
        "    response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"system\", \"content\": prompt}, #reload the prompt to keep the bot aware of it's prompt\n",
        "            *conversation_history], #changed messages to conversation_history to reload previous conversations in chatbot response\n",
        "            temperature = temp,\n",
        "            max_tokens=200,\n",
        "    )\n",
        "    query_reply = response.choices[0].message.content\n",
        "    conversation_history.append({'role': 'assistant', 'content': query_reply})\n",
        "\n",
        "    conversation_output = [] #empty conversation_output variable to put the output in and display\n",
        "\n",
        "    for i in range(0, len(conversation_history)-1, 2):   #scrolls thru and seperates user message and assistant replies from conversation history\n",
        "        user_message = conversation_history[i]['content']\n",
        "        assistant_reply = conversation_history[i+1]['content']\n",
        "        conversation_output.append((user_message, assistant_reply))\n",
        "\n",
        "    return conversation_output, \"\"\n",
        "\n",
        "css_styling = \"\"\"\n",
        "h1 {\n",
        "    font-family: 'Helvetica', sans-serif;\n",
        "    color: #4CAF50;\n",
        "    text-align: center;\n",
        "}\n",
        "h2 {\n",
        "    font-family: 'Helvetica', sans-serif;\n",
        "    color: #333;\n",
        "}\n",
        ".highlighted-text {\n",
        "    background-color: ##a38a65;\n",
        "    padding: 10px;\n",
        "    border-radius: 5px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=css_styling) as demo:\n",
        "  gr.Markdown(\"# 📝 Essay Grader\\nver.2.0\")\n",
        "\n",
        "  chatbot = gr.Chatbot()\n",
        "  essay_prompt = \"Give constructive feedback on this essay. the format for this feedback is: 'quote where the feedback came from', 'simple feedback' (e.g. 'looks good' is not descriptive). Include only three of the most important feedbacks\"\n",
        "  prompt_textbox = gr.Textbox(label=\"Prompt\", value=essay_prompt, visible=False)\n",
        "\n",
        "\n",
        "  question_textbox = gr.Textbox(label=\"Input Essay Contents Here: \", interactive=True, value=\"\", lines=10)\n",
        "  with gr.Row():\n",
        "     sent_button = gr.Button(value=\"📤 Submit Essay\", variant=\"primary\")\n",
        "     reset_button = gr.Button(value=\"🔄 Reset\", variant=\"secondary\")\n",
        "\n",
        "  sent_button.click(\n",
        "    essay_grading,\n",
        "    inputs=[prompt_textbox, question_textbox],\n",
        "    outputs=[chatbot, question_textbox]  #change output to chatbot in order to display it in the chatbot window\n",
        "   )\n",
        "\n",
        "  reset_button.click(\n",
        "    lambda: ([], \"\"),  # clear conversation history\n",
        "    inputs=[],  # clear inputs\n",
        "    outputs=[chatbot, question_textbox]  # reset chatbot\n",
        "  )\n",
        "\n",
        "demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev6R92rguhJ4"
      },
      "source": [
        "# when giving feedback, try to have it refer to where in the text the feedback is coming from.# (paragraph #, sentence, etc). Figure out how to highlight certain words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "soRqoHB1_xnH",
        "outputId": "e127aa70-a300-4b91-a389-519495f1dcec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://559128b829dd7b8a0d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://559128b829dd7b8a0d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'gradio' has no attribute 'blocks'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-14827531e91d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m# Launch the app\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mdemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, _frontend)\u001b[0m\n\u001b[1;32m   2849\u001b[0m                 \u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m             }\n\u001b[0;32m-> 2851\u001b[0;31m             \u001b[0manalytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunched_analytics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ps1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/analytics.py\u001b[0m in \u001b[0;36mlaunched_analytics\u001b[0;34m(blocks, data)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mcore_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_block_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcore_gradio_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     additional_data = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/utils.py\u001b[0m in \u001b[0;36mcore_gradio_components\u001b[0;34m()\u001b[0m\n\u001b[1;32m    645\u001b[0m     return [\n\u001b[1;32m    646\u001b[0m         \u001b[0mclass_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_all_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradio.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/utils.py\u001b[0m in \u001b[0;36mget_all_components\u001b[0;34m()\u001b[0m\n\u001b[1;32m    619\u001b[0m     classes_to_check = (\n\u001b[1;32m    620\u001b[0m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasses__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0;34m+\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlockContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasses__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m     )\n\u001b[1;32m    623\u001b[0m     \u001b[0msubclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gradio' has no attribute 'blocks'"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import gradio as gr\n",
        "from typing import List, Tuple, Dict\n",
        "from google.colab import userdata\n",
        "\n",
        "openai.api_key = userdata.get('conner').strip()\n",
        "\n",
        "def essay_grading(prompt: str, question: str, temp=1.0) -> Tuple[List[Dict[str, str]], Dict[str, List[Dict[str, int | str]]]]:\n",
        "    global conversation_history\n",
        "    conversation_history = []\n",
        "\n",
        "    conversation_history.append({'role': 'user', 'content': question})\n",
        "\n",
        "    essay_prompt = \"\"\"Give constructive feedback on this essay. The format for this feedback is: 'quote where the feedback came from', 'simple feedback' (e.g., 'looks good' is not descriptive). Include only three of the most important feedbacks.\"\"\"\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation_history],\n",
        "        temperature=temp,\n",
        "        max_tokens=200,\n",
        "    )\n",
        "    query_reply = response.choices[0].message.content\n",
        "    conversation_history.append({'role': 'assistant', 'content': query_reply})\n",
        "\n",
        "    # Parse the feedback to extract highlighted sections\n",
        "    highlighted_text = {\n",
        "        \"text\": question,  # Include the full essay text\n",
        "        \"entities\": []  # List to store highlighted sections\n",
        "    }\n",
        "\n",
        "    # Split the feedback into lines and look for the quoted text\n",
        "    for line in query_reply.split(\"\\n\"):\n",
        "        if \"'\" in line:  # Look for lines with quotes\n",
        "            quoted_text = line.split(\"'\")[1]  # Extract the quoted text\n",
        "            start_idx = question.find(quoted_text)\n",
        "            if start_idx != -1:  # Ensure the quoted text is found in the essay\n",
        "                end_idx = start_idx + len(quoted_text)\n",
        "                highlighted_text[\"entities\"].append({\"start\": start_idx, \"end\": end_idx, \"label\": \"critique\"})\n",
        "\n",
        "    conversation_output = []\n",
        "    for i in range(0, len(conversation_history) - 1, 2):\n",
        "        user_message = conversation_history[i]['content']\n",
        "        assistant_reply = conversation_history[i + 1]['content']\n",
        "        conversation_output.append({\"role\": \"user\", \"content\": user_message})\n",
        "        conversation_output.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
        "\n",
        "    return conversation_output, highlighted_text\n",
        "\n",
        "# Custom CSS for styling\n",
        "custom_css = \"\"\"\n",
        "h1 {\n",
        "    font-family: 'Helvetica', sans-serif;\n",
        "    color: #4CAF50;\n",
        "    text-align: center;\n",
        "}\n",
        "h2 {\n",
        "    font-family: 'Helvetica', sans-serif;\n",
        "    color: #333;\n",
        "}\n",
        ".highlighted-text {\n",
        "    background-color: #f0f8ff;\n",
        "    padding: 10px;\n",
        "    border-radius: 5px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=custom_css) as demo:\n",
        "    # Header\n",
        "    gr.Markdown(\"# 📝 Essay Grader\\n### Your AI-powered essay feedback tool\")\n",
        "\n",
        "    # Description\n",
        "    gr.Markdown(\"\"\"\n",
        "    Welcome to the Essay Grader! Input your essay below, and the AI will provide constructive feedback.\n",
        "    The feedback will highlight specific parts of your essay and suggest improvements.\n",
        "    \"\"\")\n",
        "\n",
        "    # Chatbot and Highlighted Text\n",
        "    with gr.Row():\n",
        "        chatbot = gr.Chatbot(label=\"AI Feedback\", height=400, type=\"messages\")  # Use type=\"messages\"\n",
        "        highlighted_text = gr.HighlightedText(label=\"Highlighted Essay\", show_legend=True)  # Remove height parameter\n",
        "\n",
        "    # Input Essay\n",
        "    question_textbox = gr.Textbox(label=\"Input Essay Contents Here: \", interactive=True, value=\"\", lines=10, placeholder=\"Paste your essay here...\")\n",
        "\n",
        "    # Controls\n",
        "    with gr.Row():\n",
        "        sent_button = gr.Button(value=\"📤 Submit Essay\", variant=\"primary\")\n",
        "        reset_button = gr.Button(value=\"🔄 Reset\", variant=\"secondary\")\n",
        "\n",
        "    # Temperature Slider\n",
        "    temp_slider = gr.Slider(minimum=0.1, maximum=1.0, value=0.7, label=\"Creativity Level (Temperature)\", step=0.1)\n",
        "\n",
        "    # Hidden Prompt\n",
        "    essay_prompt = \"\"\"Give constructive feedback on this essay. The format for this feedback is: 'quote where the feedback came from', 'simple feedback' (e.g., 'looks good' is not descriptive). Include only three of the most important feedbacks.\"\"\"\n",
        "    prompt_textbox = gr.Textbox(label=\"Prompt\", value=essay_prompt, visible=False)\n",
        "\n",
        "    # Button Actions\n",
        "    sent_button.click(\n",
        "        essay_grading,\n",
        "        inputs=[prompt_textbox, question_textbox, temp_slider],\n",
        "        outputs=[chatbot, highlighted_text]\n",
        "    )\n",
        "\n",
        "    reset_button.click(\n",
        "        lambda: ([], {\"text\": \"\", \"entities\": []}),  # Clear chatbot and highlighted text\n",
        "        inputs=[],\n",
        "        outputs=[chatbot, highlighted_text]\n",
        "    )\n",
        "\n",
        "# Launch the app\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "Q_yRvSU0TDEl",
        "outputId": "8318263d-6a1e-41e7-dc75-762da25ada7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://380a5490ef464f03f5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://380a5490ef464f03f5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generate_feedback(input_text):\n",
        "  inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
        "  output = model.generate(**inputs, max_new_tokens=100)\n",
        "  return tokenizer.decode(output[0])\n",
        "\n",
        "\n",
        "css_styling = \"\"\"\n",
        "h1 {\n",
        "    font-family: 'Helvetica', sans-serif;\n",
        "    color: #4CAF50;\n",
        "    text-align: center;\n",
        "}\n",
        ".gradio-container {\n",
        "    font-family: 'Helvetica', sans-serif;\n",
        "    text-align: center;\n",
        "}\n",
        ".gradio-textbox {\n",
        "    font-family: 'Helvetica', sans-serif;\n",
        "    text-align: center;\n",
        "    font-size: 16px;\n",
        "}\n",
        ".gradio-button {\n",
        "    font-family: 'Helvetica', sans-serif;\n",
        "    text-align: center;\n",
        "    font-size: 16px;\n",
        "    background-color: #4CAF50;\n",
        "    color: white;\n",
        "}\n",
        ".gradio-button:hover {\n",
        "    background-color: #45a049;\n",
        "    color: orange;\n",
        "}\n",
        ".gradio-button:active {\n",
        "    background-color: #3e8e3c;\n",
        "    color: white;\n",
        "}\n",
        ".hidden {\n",
        "    display: none;\n",
        "}\n",
        ".expanded {\n",
        "    height: 300px !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def show_true():\n",
        "    return gr.Textbox.update(visible=True)\n",
        "def show_false():\n",
        "    return gr.Textbox.update(visible=False)\n",
        "\n",
        "def reset_interface():\n",
        "    return (\n",
        "        gr.Textbox.update(value=\"\", lines=10, visible=True),\n",
        "        gr.Textbox.update(value=\"\", visible=True),\n",
        "        gr.Textbox.update(value=\"\", visible=True),\n",
        "        gr.Textbox.update(value=\"\", visible=True),\n",
        "        gr.Textbox.update(value=\"\", visible=False),\n",
        "        gr.Textbox.update(value=\"\", visible=False),\n",
        "        gr.Textbox.update(value=\"\", visible=False),\n",
        "        gr.Textbox.update(value=\"\", visible=False)\n",
        "    )\n",
        "\n",
        "def submit_button_updates(essay, requirements, student_id, assignment_id):\n",
        "    feedback = generate_feedback(essay)\n",
        "    return (\n",
        "        gr.Textbox.update(visible=False),\n",
        "        gr.Textbox.update(visible=False),\n",
        "        gr.Textbox.update(visible=False),\n",
        "        gr.Textbox.update(visible=False),\n",
        "        gr.Textbox.update(value=feedback, visible=True, lines=10),\n",
        "        gr.Textbox.update(visible=True),\n",
        "        gr.Textbox.update(visible=True),\n",
        "        gr.Textbox.update(visible=True)\n",
        "    )\n",
        "with gr.Blocks(css=css_styling) as demo:\n",
        "  gr.Markdown(\"# 📝 Tropos Essay Grader\")\n",
        "  question_textbox = gr.Textbox(label=\"Input Essay Contents Here: \", interactive=True, value=\"\", lines=10)\n",
        "  with gr.Row():\n",
        "     requirements_input = gr.Textbox(label=\"Rubric / Requirements: \", interactive=True, value=\"\", lines=3)\n",
        "  with gr.Row():\n",
        "     student_id_textbox = gr.Textbox(label=\"Student ID: \", interactive=True, value=\"\", lines=1)\n",
        "     assignment_id_textbox = gr.Textbox(label=\"Assignment ID: \", interactive=True, value=\"\", lines=1)\n",
        "  with gr.Row():\n",
        "     sent_button = gr.Button(value=\"📤 Submit Essay\", variant=\"primary\")\n",
        "     reset_button = gr.Button(value=\"🔄 Reset\", variant=\"secondary\")\n",
        "  with gr.Column():\n",
        "    feedback_textbox = gr.Textbox(label=\"Essay Feedback\", interactive=False, value=\"\", lines=5, visible = False)\n",
        "  with gr.Row():\n",
        "    inline_textbox1 = gr.Textbox(label=\"Inline Feedback\", interactive=False, value=\"\", lines=3, visible = False)\n",
        "    inline_textbox2 = gr.Textbox(label=\"Inline Feedback\", interactive=False, value=\"\", lines=3, visible = False)\n",
        "    inline_textbox3 = gr.Textbox(label=\"Inline Feedback\", interactive=False, value=\"\", lines=3, visible = False)\n",
        "\n",
        "\n",
        "  sent_button.click(\n",
        "    submit_button_updates,\n",
        "    inputs=[question_textbox, requirements_input, student_id_textbox, assignment_id_textbox],\n",
        "    outputs=[question_textbox, requirements_input, student_id_textbox, assignment_id_textbox, feedback_textbox, inline_textbox1, inline_textbox2, inline_textbox3],\n",
        "    )\n",
        "  reset_button.click(\n",
        "    reset_interface,  # Clear all inputs and feedback\n",
        "    inputs=[],  # clear inputs\n",
        "    outputs=[question_textbox, feedback_textbox, assignment_id_textbox, student_id_textbox, requirements_input, inline_textbox1, inline_textbox2, inline_textbox3])\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNaXjSzyTM6Y"
      },
      "source": [
        "MAKE A INPUT CLASS AND STUFF -- USING EXAMPLE JOSH (@Oxulotl)\n",
        " GAVE IN DISCORD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "b6kXhbQbTWTg",
        "outputId": "6f3b943a-5f24-4787-80dc-4c6c4b29e853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://1f1be7b85561dcad02.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://1f1be7b85561dcad02.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7898 <> https://1f1be7b85561dcad02.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import json\n",
        "\n",
        "# Define InputFields and OutputFields classes\n",
        "class InputFields:\n",
        "    def __init__(self):\n",
        "        self._student_id = None\n",
        "        self._assignment_id = None\n",
        "        self._requirements_input = None\n",
        "        self._student_essay = None\n",
        "\n",
        "    # getters\n",
        "    def get_student_id(self):\n",
        "        return self._student_id\n",
        "\n",
        "    def get_assignment_id(self):\n",
        "        return self._assignment_id\n",
        "\n",
        "    def get_requirements_input(self):\n",
        "        return self._requirements_input\n",
        "\n",
        "    def get_student_essay(self):\n",
        "        return self._student_essay\n",
        "\n",
        "    #setters\n",
        "    def set_student_id(self, value):\n",
        "        self._student_id = value\n",
        "\n",
        "    def set_assignment_id(self, value):\n",
        "        self._assignment_id = value\n",
        "\n",
        "    def set_requirements_input(self, value):\n",
        "        self._requirements_input = value\n",
        "\n",
        "    def set_student_essay(self, value):\n",
        "        self._student_essay = value\n",
        "\n",
        "    #adder methods (builder method)\n",
        "    def add_student_id(self, value):\n",
        "        self._student_id = value\n",
        "        return self\n",
        "\n",
        "    def add_assignment_id(self, value):\n",
        "        self._assignment_id = value\n",
        "        return self\n",
        "\n",
        "    def add_requirements_input(self, value):\n",
        "        self._requirements_input = value\n",
        "        return self\n",
        "\n",
        "    def add_student_essay(self, value):\n",
        "        self._student_essay = value\n",
        "        return self\n",
        "\n",
        "    # JSON parsing and serialization\n",
        "    @staticmethod\n",
        "    def from_json(json_str):\n",
        "        data = json.loads(json_str)\n",
        "        obj = InputFields()\n",
        "        obj.set_student_id(data.get(\"StudentID\"))\n",
        "        obj.set_assignment_id(data.get(\"AssignmentID\"))\n",
        "        obj.set_requirements_input(data.get(\"Requirements Input\"))\n",
        "        obj.set_student_essay(data.get(\"Student Essay\"))\n",
        "        return obj\n",
        "\n",
        "    def to_json(self):\n",
        "        return json.dumps({\n",
        "            \"StudentID\": self._student_id,\n",
        "            \"AssignmentID\": self._assignment_id,\n",
        "            \"Requirements Input\": self._requirements_input,\n",
        "            \"Student Essay\": self._student_essay\n",
        "        }, indent=4)\n",
        "\n",
        "class OutputFields:\n",
        "    def __init__(self):\n",
        "        self._student_id = None\n",
        "        self._assignment_id = None\n",
        "        self._text_snippet = None\n",
        "        self._feedback = None\n",
        "        self._feedback_type = None\n",
        "\n",
        "    # Getters\n",
        "    def get_student_id(self):\n",
        "        return self._student_id\n",
        "\n",
        "    def get_assignment_id(self):\n",
        "        return self._assignment_id\n",
        "\n",
        "    def get_text_snippet(self):\n",
        "        return self._text_snippet\n",
        "\n",
        "    def get_feedback(self):\n",
        "        return self._feedback\n",
        "\n",
        "    def get_feedback_type(self):\n",
        "        return self._feedback_type\n",
        "\n",
        "    # Setters\n",
        "    def set_student_id(self, value):\n",
        "        self._student_id = value\n",
        "\n",
        "    def set_assignment_id(self, value):\n",
        "        self._assignment_id = value\n",
        "\n",
        "    def set_text_snippet(self, value):\n",
        "        self._text_snippet = value\n",
        "\n",
        "    def set_feedback(self, value):\n",
        "        self._feedback = value\n",
        "\n",
        "    def set_feedback_type(self, value):\n",
        "        self._feedback_type = value\n",
        "\n",
        "    # Builder methods (adders)\n",
        "    def add_student_id(self, value):\n",
        "        self._student_id = value\n",
        "        return self\n",
        "\n",
        "    def add_assignment_id(self, value):\n",
        "        self._assignment_id = value\n",
        "        return self\n",
        "\n",
        "    def add_text_snippet(self, value):\n",
        "        self._text_snippet = value\n",
        "        return self\n",
        "\n",
        "    def add_feedback(self, value):\n",
        "        self._feedback = value\n",
        "        return self\n",
        "\n",
        "    def add_feedback_type(self, value):\n",
        "        self._feedback_type = value\n",
        "        return self\n",
        "\n",
        "    # JSON parsing and serialization\n",
        "    @staticmethod\n",
        "    def from_json(json_str):\n",
        "        data = json.loads(json_str)\n",
        "        obj = OutputFields()\n",
        "        obj.set_student_id(data.get(\"Student ID\"))\n",
        "        obj.set_assignment_id(data.get(\"Assignment ID\"))\n",
        "        obj.set_text_snippet(data.get(\"Text Snippet\"))\n",
        "        obj.set_feedback(data.get(\"Feedback\"))\n",
        "        obj.set_feedback_type(data.get(\"FeedbackType\"))\n",
        "        return obj\n",
        "\n",
        "    def to_json(self):\n",
        "        return json.dumps({\n",
        "            \"Student ID\": self._student_id,\n",
        "            \"Assignment ID\": self._assignment_id,\n",
        "            \"Text Snippet\": self._text_snippet,\n",
        "            \"Feedback\": self._feedback,\n",
        "            \"FeedbackType\": self._feedback_type\n",
        "        })\n",
        "\n",
        "\n",
        "# Dummy feedback\n",
        "def generate_feedback(input_text):\n",
        "    #filler code\n",
        "    return f\"Feedback for: {input_text}\"\n",
        "\n",
        "\n",
        "# Custom CSS for styling\n",
        "css_styling = \"\"\"\n",
        "h1 {\n",
        "    font-family: 'Helvetica', sans-serif;\n",
        "    color: #4CAF50;\n",
        "    text-align: center;\n",
        "}\n",
        ".gradio-container {\n",
        "    font-family: 'Helvetica', sans-serif;\n",
        "    text-align: center;\n",
        "}\n",
        ".gradio-textbox {\n",
        "    font-family: 'Helvetica', sans-serif;\n",
        "    text-align: center;\n",
        "    font-size: 16px;\n",
        "}\n",
        ".gradio-button {\n",
        "    font-family: 'Helvetica', sans-serif;\n",
        "    text-align: center;\n",
        "    font-size: 16px;\n",
        "    background-color: #4CAF50;\n",
        "    color: white;\n",
        "}\n",
        ".gradio-button:hover {\n",
        "    background-color: #45a049;\n",
        "    color: orange;\n",
        "}\n",
        ".gradio-button:active {\n",
        "    background-color: #3e8e3c;\n",
        "    color: white;\n",
        "}\n",
        ".hidden {\n",
        "    display: none;\n",
        "}\n",
        ".expanded {\n",
        "    height: 300px !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def reset_interface():\n",
        "    return (\n",
        "        gr.update(value=\"\", visible=True),  #essay textbox\n",
        "        gr.update(value=\"\", visible=True),  # requirements\n",
        "        gr.update(value=\"\", visible=True),  # student ID\n",
        "        gr.update(value=\"\", visible=True),  # assignment ID\n",
        "        gr.update(value=\"\", visible=False),  #feedback\n",
        "        gr.update(value=\"\", visible=False),  # inline feedback 1\n",
        "        gr.update(value=\"\", visible=False),  # inline feedback 2\n",
        "        gr.update(value=\"\", visible=False)   #inline feedback 3\n",
        "    )\n",
        "\n",
        "\n",
        "def submit_button_updates(essay, requirements, student_id, assignment_id):\n",
        "    input_data = InputFields() \\\n",
        "        .add_student_id(student_id) \\\n",
        "        .add_assignment_id(assignment_id) \\\n",
        "        .add_requirements_input(requirements) \\\n",
        "        .add_student_essay(essay)\n",
        "\n",
        "    feedback = generate_feedback(input_data.get_student_essay())#feedback\n",
        "\n",
        "    output_data = OutputFields() \\\n",
        "        .add_student_id(input_data.get_student_id()) \\\n",
        "        .add_assignment_id(input_data.get_assignment_id()) \\\n",
        "        .add_text_snippet(input_data.get_student_essay()) \\\n",
        "        .add_feedback(feedback) \\\n",
        "        .add_feedback_type(\"Constructive\")  #feedback type\n",
        "\n",
        "    return (\n",
        "        gr.update(visible=False),  #essay input\n",
        "        gr.update(visible=False),  #rubric/requirements\n",
        "        gr.update(visible=False),  #student ID\n",
        "        gr.update(visible=False),  #assignment ID\n",
        "        gr.update(value=output_data.get_feedback(), visible=True, lines=10),  #feedback\n",
        "        gr.update(visible=True),  #inline feedback 1\n",
        "        gr.update(visible=True),  #inline feedback 2\n",
        "        gr.update(visible=True)   #inline feedback 3\n",
        "    )\n",
        "\n",
        "\n",
        "with gr.Blocks(css=css_styling) as demo:\n",
        "\n",
        "    gr.Markdown(\"# 📝 Tropos Essay Grader\")\n",
        "    question_textbox = gr.Textbox(label=\"Input Essay Contents Here: \", interactive=True, value=\"\", lines=10)\n",
        "    requirements_input = gr.Textbox(label=\"Rubric / Requirements: \", interactive=True, value=\"\", lines=3)\n",
        "\n",
        "    with gr.Row():\n",
        "        student_id_textbox = gr.Textbox(label=\"Student ID: \", interactive=True, value=\"\", lines=1)\n",
        "        assignment_id_textbox = gr.Textbox(label=\"Assignment ID: \", interactive=True, value=\"\", lines=1)\n",
        "\n",
        "    with gr.Row():\n",
        "        sent_button = gr.Button(value=\"📤 Submit Essay\", variant=\"primary\")\n",
        "        reset_button = gr.Button(value=\"🔄 Reset\", variant=\"secondary\")\n",
        "\n",
        "    feedback_textbox = gr.Textbox(label=\"Essay Feedback\", interactive=False, value=\"\", lines=5, visible=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        inline_textbox1 = gr.Textbox(label=\"Inline Feedback\", interactive=False, value=\"\", lines=3, visible=False)\n",
        "        inline_textbox2 = gr.Textbox(label=\"Inline Feedback\", interactive=False, value=\"\", lines=3, visible=False)\n",
        "        inline_textbox3 = gr.Textbox(label=\"Inline Feedback\", interactive=False, value=\"\", lines=3, visible=False)\n",
        "\n",
        "    sent_button.click(\n",
        "        submit_button_updates,\n",
        "        inputs=[question_textbox, requirements_input, student_id_textbox, assignment_id_textbox],\n",
        "        outputs=[question_textbox, requirements_input, student_id_textbox, assignment_id_textbox, feedback_textbox, inline_textbox1, inline_textbox2, inline_textbox3],\n",
        "    )\n",
        "\n",
        "    reset_button.click(\n",
        "        reset_interface,  \n",
        "        inputs=[],  # clear inputs\n",
        "        outputs=[question_textbox, requirements_input, student_id_textbox, assignment_id_textbox, feedback_textbox, inline_textbox1, inline_textbox2, inline_textbox3]\n",
        "    )\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(debug = True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
